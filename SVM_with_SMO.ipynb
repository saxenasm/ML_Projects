{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Support Vector Machine using Sequential Minimization Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import prettytable\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining class Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportVectorMachine():\n",
    "    \"\"\"\n",
    "    construtor to initialize values for features and labels array \n",
    "    x and y respectively as well as lagrange multiplier α and bias b\n",
    "    \"\"\"\n",
    "    def __init__ (self,x,y):\n",
    "        self._x =x\n",
    "        self._y=y\n",
    "        self._alpha= np.mat(np.zeros((len(x),1)), dtype='float32')\n",
    "        self._b =np.mat([[0]])\n",
    "        \n",
    "        i=0\n",
    "        p=0\n",
    "        while(i< max_iter):\n",
    "#             if((i%10==0)&(i>0)):\n",
    "#                 #progress bar after 10 iterations\n",
    "#                 sys.stdout.write('='+ str(i))\n",
    "#                 p=i%10\n",
    "#                 sys.stdout.flush()\n",
    "\n",
    "            if(self.perform_smo()==0): i+=1\n",
    "            else: i=0\n",
    "        \n",
    "        self._w =self.calculate_w(np.nan_to_num(self._alpha), self._x,self._y)\n",
    "    def perform_smo(self):\n",
    "        \"\"\"\n",
    "        for this SMO algorthim we optimise taking random pairs of alpha\n",
    "        such that they obey the constaint ∑i=1-l(yiαi)= 0. and at the same time maximise the \n",
    "        decision margin ||w||^2\n",
    "        \"\"\"\n",
    "        numberAlphaPairsOptimized=0\n",
    "        \n",
    "        for i in range(0,len(self._x)):\n",
    "            \"\"\"\n",
    "             Calculate the weight vector w= ∑i=1-l(αi yi xi)\n",
    "             Ei= ∑j=1-l (αj yj K(xi, xj) +b) −yi, i= 1,2 \n",
    "             Standard polynomial Kernelf fucntion K on S*S is of form, (a*b +r)^d \n",
    "             here ,d=1,r=0 , which gives\n",
    "             Kij = K(xi ,xj)= (x1. x2) ,dot product \n",
    "\n",
    "            \"\"\"    \n",
    "           \n",
    "            Ei =np.multiply(self._y , self._alpha).T* \\\n",
    "                self._x *self._x[i].T + self._b - self._y[i]\n",
    "            #print(Ei)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            KKT(i) =α(i){yi(〈w, xi〉+b)−1}\n",
    "            if α=0 , corrreclty classified,\n",
    "            α=c, misclassified or in the margin, c is slack parameter\n",
    "            0<α<c , example is support vector\n",
    "            \n",
    "            \"\"\"\n",
    "            if(self.bool_alpha_violates_KKT(self._alpha[i],Ei)):\n",
    "                \n",
    "                j= self.select_second_alpha_to_optimise(i, len(self._x))\n",
    "                Ej =np.multiply(self._y , self._alpha).T* \\\n",
    "                self._x *self._x[j].T + self._b - self._y[j]\n",
    "                #print(Ej)\n",
    "                alphaIold= self._alpha[i].copy()\n",
    "                alphaJold= self._alpha[j].copy()\n",
    "                \n",
    "                bounds= self.bounds_alpha(self._alpha[i],self._alpha[j], self._y[i], self._y[j])\n",
    "                \"\"\"\n",
    "                Calculate k= K11+K22−2∗K12\n",
    "                \"\"\" \n",
    "                k= 2.0* self._x[i] * self._x[j].T \\\n",
    "                    -self._x[j] * self._x[i].T \\\n",
    "                    -self._x[j] * self._x[j].T\n",
    "                \n",
    "                if bounds[0]!=bounds[1] and k<0:\n",
    "                    if self.optimise_alpha_pair(i,j, Ei, Ej, k, bounds, alphaIold, alphaJold):\n",
    "                        numberAlphaPairsOptimized+=1\n",
    "                    \n",
    "\n",
    "                \n",
    "        return numberAlphaPairsOptimized\n",
    "    \n",
    "    def optimise_alpha_pair( self, i,j, Ei, Ej, k, bounds, alphaIold, alphaJold):\n",
    "        \"\"\"\n",
    "        upadte alpha 2 as - α2(new)= α2(old)+y2 * e(2)/k\n",
    "        \"\"\"\n",
    "        flag=False\n",
    "        self._alpha[j]-= self._y[j] * (Ei- Ej)/k\n",
    "        self.clipAlpha_j(j,bounds)\n",
    "        if(abs(self._alpha[j] -alphaJold)>= min_alpha_optimisation):\n",
    "            self.optimiseAlphaIandAlphajOppDir(i,j,alphaJold)\n",
    "            self.optimise_b(Ei,Ej, alphaIold,alphaJold,i,j)\n",
    "            flag=True\n",
    "        return flag\n",
    "    \n",
    "    def optimise_b(self, Ei, Ej, alphaIold, alphaJold, i,j):\n",
    "        b1= self._b - Ei- self._y[i] *\\\n",
    "        (self._alpha[i]- alphaIold) * self._x[i] * self._x[i].T \\\n",
    "        - self._y[j] * (self._alpha[j]- alphaJold) * self._x[i] * self._x[j].T\n",
    "        \n",
    "        b2= self._b - Ej- self._y[i] *\\\n",
    "        (self._alpha[i]- alphaIold) * self._x[i] * self._x[j].T \\\n",
    "        - self._y[j] * (self._alpha[j]- alphaJold) * self._x[j] * self._x[j].T\n",
    "        if(0< self._alpha[i]) and (c> self._alpha[i]): self._b=b1\n",
    "        elif (0< self._alpha[j]) and (c> self._alpha[j]): self._b=b2\n",
    "        else: self.b= (b1+b2)/2.0\n",
    "            \n",
    "            \n",
    "    def bool_alpha_violates_KKT(self,alpha, E):\n",
    "        c1=( alpha>0 and np.abs(E)< EPSILON)\n",
    "        c2=(alpha<c and np.abs(E) > EPSILON)\n",
    "        return c1 or c2\n",
    "    \n",
    "    def select_second_alpha_to_optimise(self, idxFirstAlpha, numRows):\n",
    "        idxSecondAlpha =idxFirstAlpha\n",
    "        while(idxFirstAlpha==idxSecondAlpha):\n",
    "            idxSecondAlpha= int(np.random.uniform(0,numRows))\n",
    "        \n",
    "        return idxSecondAlpha\n",
    "    \n",
    "    def optimiseAlphaIandAlphajOppDir(self, i, j, alphaJold):\n",
    "        \"\"\"\n",
    "        upadte alpha 1 as- α1(new)= α1(old)+y1y2(α2(old)−α2(new))\n",
    "        \"\"\"\n",
    "        self._alpha[i]+= self._y[j] + self._y[i] * (alphaJold - self._alpha[j])\n",
    "    \n",
    "    def clipAlpha_j(self,j,bounds):\n",
    "        if self._alpha[j]< bounds[0]: self._alpha[j]=bounds[0]\n",
    "        if self._alpha[j] > bounds[1] : self._alpha[j]= bounds[1]\n",
    "            \n",
    "    \n",
    "    def bounds_alpha(self,alphai , alphaj , yi , yj):\n",
    "        bounds=[2]\n",
    "        if(yi==yj):\n",
    "            bounds.insert(0,max(0,alphaj+ alphai -c))\n",
    "            bounds.insert(1, min(c, alphaj +alphai))\n",
    "        else:\n",
    "            bounds.insert(0, max(0, alphaj- alphai))\n",
    "            bounds.insert(1, min(c,alphaj - alphai)+ c)\n",
    "        return bounds\n",
    "    \n",
    "    def classification(self,x):\n",
    "        classification = \"class -1 negative\"\n",
    "#         return(x, self._w, self._b)\n",
    "        wxb =(np.asarray(x).astype('float32',casting='unsafe') @ self._w + self._b).item(0,0)\n",
    "        if(np.sign (wxb)==1):\n",
    "            classification =\"class +1 positive\"\n",
    "        return classification,wxb\n",
    "    def get_alpha(self): return self._alpha\n",
    "    def get_b(self): return self._b\n",
    "    def get_w(self): return self._w\n",
    "    \n",
    "    def calculate_w( self, alpha, x,y):\n",
    "        \"\"\"\n",
    "             Calculate the weight vector w= ∑i=1-l(αi*yi*xi)\n",
    "        \"\"\"\n",
    "        w=np.zeros((np.shape(x)[1],1))\n",
    "        #print(np.nan_to_num(alpha))\n",
    "        for i in range(len(x)):\n",
    "            w+= np.nan_to_num(np.multiply(y[i]* alpha[i] , x[i].T))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('SVMdataTest.txt')\n",
    "data.columns=['data']\n",
    "data['x1']=data.data.str.split().str[0].astype(int)\n",
    "data['x2']=data.data.str.split().str[1].astype(int)\n",
    "data['y']=data.data.str.split().str[2].astype(int)\n",
    "data=data.drop(columns={'data'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SVM on dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter=1000 #max attempts to optimise \n",
    "c=0.01 #slack parameter\n",
    "min_alpha_optimisation=0.01 ## how much minimum pair of alpha shoud  optimise in order to consider alpha pair optimized\n",
    "EPSILON= 0.0001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##shuffle train dataset\n",
    "index = data.index\n",
    "data=shuffle(data)\n",
    "data.index=index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit SVM on linearly separble binary class data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data[['x1','x2']]\n",
    "yArray=data['y']\n",
    "#xArray=normalize(X, norm='max', axis=0)\n",
    "xArray=np.asarray(X)\n",
    "#xArray=xArray.astype('float32',casting='unsafe').round(7)\n",
    "#yArray=[+1 if x==1 else -1 for x in yArray]\n",
    "\n",
    "svm= SupportVectorMachine(np.mat(xArray[0:200]), np.mat(yArray[0:200]).transpose())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display support vectors , class labels ,alpha values and weights learned by model for x1 and x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------------+\n",
      "| Support Vector | label |         alpha          |\n",
      "+----------------+-------+------------------------+\n",
      "|   [270 300]    |   1   | 3.370608965269639e-06  |\n",
      "|   [165 195]    |   1   | 4.150081440457143e-05  |\n",
      "|   [235 211]    |   -1  | 0.0002837955253198743  |\n",
      "|   [111  90]    |   -1  | 0.00042558982386253774 |\n",
      "|    [66 93]     |   1   | 0.00014853286847937852 |\n",
      "|   [147 122]    |   -1  | 2.794317333609797e-05  |\n",
      "|   [147 175]    |   1   | 0.0008821747032925487  |\n",
      "|   [275 241]    |   -1  | 9.002593287732452e-05  |\n",
      "|   [182 156]    |   -1  | 0.0003094676067121327  |\n",
      "|    [79 50]     |   -1  | 6.777705857530236e-05  |\n",
      "|    [47 75]     |   1   | 0.0004292913363315165  |\n",
      "+----------------+-------+------------------------+\n",
      "+-----------------------------+-------+\n",
      "|              wT             |   b   |\n",
      "+-----------------------------+-------+\n",
      "| [[-0.03705745  0.03453977]] | [[0]] |\n",
      "+-----------------------------+-------+\n",
      "close window to proceed\n"
     ]
    }
   ],
   "source": [
    "alpha=svm.get_alpha()\n",
    "def display_info_tables():\n",
    "    svTable= prettytable.PrettyTable(['Support Vector','label','alpha'])\n",
    "    for i in range(len(xArray[:200])):\n",
    "        if ((alpha[i]>0.0) and (alpha[i]!=c)):\n",
    "            svTable.add_row([xArray[i], yArray[i], alpha[i].item()])\n",
    "    print(svTable)\n",
    "    wbTable=prettytable.PrettyTable(['wT','b'])\n",
    "    wbTable.add_row([svm.get_w().T, svm.get_b()])\n",
    "    print(wbTable)\n",
    "display_info_tables()\n",
    "print('close window to proceed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weight of both x1 and x2 are -0.04360495 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test code on remaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  0],\n",
       "       [ 0, 32]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### test data #####\n",
    "act= yArray[200:]\n",
    "\n",
    "pred=[]\n",
    "###### getting predictions #######\n",
    "for k in xArray[200:]:  \n",
    "    t=svm.classification(k)\n",
    "    #print(t[1])\n",
    "    if(t[0]=='class +1 positive'):\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(-1)\n",
    "\n",
    "##### saving parameter values and output in datframe ######\n",
    "t0=confusion_matrix(act,pred)\n",
    "t0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Precision 100% , Recal 100% , data is completely linearly separble and tested through 65 rows and trained on 200 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional testing of SVMwSMO on sklearn breast cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "max_iter=5000 #max attempts to optimise \n",
    "c=100 #slack parameter\n",
    "min_alpha_optimisation=0.000001\n",
    "EPSILON= 0.001\n",
    "\n",
    "df=pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "df1=pd.DataFrame(data['target'], columns=['target'])\n",
    "df=pd.concat([df,df1],axis=1)\n",
    "\n",
    "index = df.index\n",
    "df=shuffle(df)\n",
    "df.index=index\n",
    "\n",
    "X=df[['mean concave points',\n",
    " 'area error',\n",
    " 'worst concave points',\n",
    " 'worst radius',\n",
    " 'mean concavity',\n",
    " 'worst perimeter',\n",
    " 'mean area']]\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X=scaler.transform(X)\n",
    "\n",
    "# pca = PCA()\n",
    "# pca.fit(X)\n",
    "# x_new = pca.transform(X) \n",
    "    \n",
    "# xArray, yArray= x_new[0:400], (df['target'].loc[0:399])\n",
    "yArray=df['target']\n",
    "xArray=normalize(X, norm='max', axis=0)\n",
    "\n",
    "xArray=xArray.astype('float32',casting='unsafe').round(7)\n",
    "yArray=[+1 if x==1 else -1 for x in yArray]\n",
    "\n",
    "svm= SupportVectorMachine(np.mat(xArray[0:400]), np.mat(yArray[0:400]).transpose())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained on 400 rows and tested on 200 rows, confusion matrix looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 54],\n",
       "       [28, 87]], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### test data #####\n",
    "act= yArray[400:]\n",
    "\n",
    "pred=[]\n",
    "###### getting predictions #######\n",
    "for k in xArray[400:]:  \n",
    "    t=svm.classification(k)\n",
    "    #print(t[1])\n",
    "    if(t[0]=='class +1 positive'):\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(-1)\n",
    "\n",
    "##### saving parameter values and output in datframe ######\n",
    "t0=confusion_matrix(act,pred)\n",
    "t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid on hyperparmeters  epsilon, slack parameter and min_alpha_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=0%==0%==0%==1%==1%==1%==1%==2%==2%==2%==2%==3%==3%==3%==3%==3%==4%==4%==4%==4%==5%==5%==5%==5%==6%==6%==6%==6%==6%==7%==7%==7%==7%==8%==8%==8%==8%==9%==9%==9%==9%==9%==10%==10%==10%==10%==11%==11%==11%==11%==12%==12%==12%==12%==12%==13%==13%==13%==13%==14%==14%==14%==14%==15%==15%==15%==15%==16%==16%==16%==16%==16%==17%==17%==17%==17%==18%==18%==18%==18%==19%==19%==19%==19%==19%==20%==20%==20%==20%==21%==21%==21%==21%==22%==22%==22%==22%==22%==23%==23%==23%==23%==24%==24%==24%==24%==25%==25%==25%==25%==25%==26%==26%==26%==26%==27%==27%==27%==27%==28%==28%==28%==28%==28%==29%==29%==29%==29%==30%==30%==30%==30%==31%==31%==31%==31%==31%==32%==32%==32%==32%==33%==33%==33%==33%==34%==34%==34%==34%==34%==35%==35%==35%==35%==36%==36%==36%==36%==37%==37%==37%==37%==38%==38%==38%==38%==38%==39%==39%==39%==39%==40%==40%==40%==40%==41%==41%==41%==41%==41%==42%==42%==42%==42%==43%==43%==43%==43%==44%==44%==44%==44%==44%==45%==45%==45%==45%==46%==46%==46%==46%==47%==47%==47%==47%==47%==48%==48%==48%==48%==49%==49%==49%==49%==50%==50%==50%==50%==50%==51%==51%==51%==51%==52%==52%==52%==52%==53%==53%==53%==53%==53%==54%==54%==54%==54%==55%==55%==55%==55%==56%==56%==56%==56%==56%==57%==57%==57%==57%==58%==58%==58%==58%==59%==59%==59%==59%==59%==60%==60%==60%==60%==61%==61%==61%==61%==62%==62%==62%==62%==62%==63%==63%==63%==63%==64%==64%==64%==64%==65%==65%==65%==65%==66%==66%==66%==66%==66%==67%==67%==67%==67%==68%==68%==68%==68%==69%==69%==69%==69%==69%==70%==70%==70%==70%==71%==71%==71%="
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-316-2ae650876c5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[0msvm\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mSupportVectorMachine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[0men\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-211-9e46e8f77ac1>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#                 sys.stdout.flush()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperform_smo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-211-9e46e8f77ac1>\u001b[0m in \u001b[0;36mperform_smo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimise_alpha_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphaIold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphaJold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m                         \u001b[0mnumberAlphaPairsOptimized\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-211-9e46e8f77ac1>\u001b[0m in \u001b[0;36moptimise_alpha_pair\u001b[1;34m(self, i, j, Ei, Ej, k, bounds, alphaIold, alphaJold)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0malphaJold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m \u001b[0mmin_alpha_optimisation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimiseAlphaIandAlphajOppDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaJold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimise_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphaIold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphaJold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[0mflag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-211-9e46e8f77ac1>\u001b[0m in \u001b[0;36moptimise_b\u001b[1;34m(self, Ei, Ej, alphaIold, alphaJold, i, j)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mb1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_b\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mEi\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m        \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0malphaIold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m         \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0malphaJold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mb2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_b\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mEj\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m        \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0malphaIold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m         \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0malphaJold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__rmul__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### test data #####\n",
    "act= np.asarray(df['target'].loc[200:])\n",
    "act=[+1 if x==1 else -1 for x in act]\n",
    "\n",
    "##### parameter sarch ######\n",
    "para= pd.DataFrame(columns= ['max_iter','min_alpha_optimization','epsilon','slack_parameter','TN', 'FP', 'FN', 'TP', 'iter_time'])\n",
    "i=0\n",
    "#### grid search on parameters\n",
    "for max_iter in [1000, 2000, 10000]:\n",
    "    for min_alpha_optimisation in [1e-1 , 1e-2, 1e-3 , 1e-4, 1e-5, 1e-6]:\n",
    "        for EPSILON in [1,0.1, 0.01, 0.001, 1e-4, 1e-5]:\n",
    "            for c in [0.1, 0.01, 1, 10]:\n",
    "                sys.stdout.write('='+ str(round(100*(i/432))) +'%=')\n",
    "                sys.stdout.flush()\n",
    "                st=time.time()\n",
    "                svm= SupportVectorMachine(np.mat(xArray), np.mat(yArray).transpose())\n",
    "                en= time.time()\n",
    "                pred=[]\n",
    "                ###### getting predictions #######\n",
    "                for k in range(200, df.shape[0]):  \n",
    "                    t=svm.classification(df[['worst perimeter','worst concave points','mean concave points','worst area','worst radius','mean texture',\n",
    "      'worst compactness']])\n",
    "                    if(t[0]=='class +1 positive'):\n",
    "                        pred.append(1)\n",
    "                    else:\n",
    "                        pred.append(-1)\n",
    "                \n",
    "                ##### saving parameter values and output in datframe ######\n",
    "                t0=confusion_matrix(act,pred)\n",
    "                para.loc[i]= [max_iter, min_alpha_optimisation, EPSILON, c, t0[0][0], t0[0][1], t0[1][0], t0[1][1],round(en-st)]\n",
    "                #print(para)\n",
    "                i+=1\n",
    "\n",
    "para.to_csv('gridSearchSVMParameters.csv')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para.to_csv('gridSearchSVMParameters.csv')\n",
    "para['accuracy']=   round(100*((para['TP']+ para['TN'])/( para['TP']+ para['FP'] + para['TN']+ para['FN'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the most important features from breast cancer data coming from random forest regression and only using those to train SVM algorthim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying sklearn SVM to compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 55],\n",
       "       [31, 73]], dtype=int64)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "df=pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "df1=pd.DataFrame(data['target'], columns=['target'])\n",
    "df=pd.concat([df,df1],axis=1)\n",
    "from sklearn.utils import shuffle\n",
    "index = df.index\n",
    "df=shuffle(df)\n",
    "df.index=index\n",
    "clf = svm.SVC()\n",
    "X=normalize(data['data'][0:400], norm='max', axis=0)\n",
    "Y=data['target'][0:400]\n",
    "Y=[+1 if x==1 else -1 for x in Y]\n",
    "clf.fit(X,Y )\n",
    "x=normalize(data['data'][400:], norm='max', axis=0)\n",
    "\n",
    "pred=clf.predict(x)\n",
    "\n",
    "act= np.asarray(df['target'].loc[400:])\n",
    "act=[+1 if x==1 else -1 for x in act]\n",
    "confusion_matrix(act,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Reandom Forest Regressor to get the best set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df=pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "df1=pd.DataFrame(data['target'], columns=['target'])\n",
    "df=pd.concat([df,df1],axis=1)\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "\n",
    "regr = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "regr.fit(df.loc[:, :'worst fractal dimension'], df['target'])\n",
    "\n",
    "\n",
    "t=pd.DataFrame(columns={'imp','features'})\n",
    "t['imp']=regr.feature_importances_\n",
    "t['features']=df.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean concave points',\n",
       " 'area error',\n",
       " 'worst concave points',\n",
       " 'worst radius',\n",
       " 'mean concavity',\n",
       " 'worst perimeter',\n",
       " 'mean area']"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sort_values(by='imp',ascending=False)[0:7].features.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "USe the above features to train the SVM as dimentionality poses threat to convergence of SV algorthim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
